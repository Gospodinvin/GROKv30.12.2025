# predictor.py
import httpx
import os
import logging
from features import build_features
from patterns import detect_patterns
from trend import trend_signal, market_regime
from confidence import confidence_from_probs
from model_registry import get_model
from data_provider import get_candles
from cv_extractor import extract_candles
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Grok API
XAI_API_KEY = os.getenv("XAI_API_KEY")
GROK_MODEL = "grok-4"  # –∏–ª–∏ "grok-beta" / "grok-4" –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏

async def call_grok(candles: list, patterns: list, regime: str, tf: str, symbol: str) -> float:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ Grok API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞.
    """
    if not XAI_API_KEY:
        logging.warning("XAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî Grok –æ—Ç–∫–ª—é—á—ë–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0.5")
        return 0.5

    recent_candles = candles[-10:]
    candle_desc = []
    for i, c in enumerate(recent_candles):
        direction = "üü¢" if c["close"] > c["open"] else "üî¥"
        body = abs(c["close"] - c["open"])
        candle_desc.append(
            f"{i+1}: {direction} O:{c['open']:.4f} H:{c['high']:.4f} L:{c['low']:.4f} C:{c['close']:.4f} (body {body:.4f})"
        )

    prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä—ã–Ω–∫–æ–≤.
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {symbol}
–¢–∞–π–º—Ñ—Ä–µ–π–º: {tf} –º–∏–Ω—É—Ç
–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º —Ä—ã–Ω–∫–∞: {regime}

–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–≤–µ—á–µ–π (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ü–µ–Ω—ã):
{"\n".join(candle_desc)}

–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {", ".join(patterns) if patterns else "–Ω–µ—Ç"}

–î–∞–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ —Ü–µ–Ω—ã –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ 2‚Äì3 —Å–≤–µ—á–∏.
–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ–¥–Ω–∏–º —á–∏—Å–ª–æ–º –æ—Ç 0.00 –¥–æ 1.00 (–Ω–∞–ø—Ä–∏–º–µ—Ä: 0.68).
–ë–µ–∑ —Ç–µ–∫—Å—Ç–∞, –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏ —Å–∏–º–≤–æ–ª–æ–≤.
"""

    try:
        async with httpx.AsyncClient(timeout=15.0) as client:
            response = await client.post(
                "https://api.x.ai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {XAI_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": GROK_MODEL,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.3,
                    "max_tokens": 10
                }
            )

            if response.status_code == 200:
                text = response.json()["choices"][0]["message"]["content"].strip()
                try:
                    prob = float(text)
                    if 0.0 <= prob <= 1.0:
                        logging.info(f"Grok –≤–µ—Ä–Ω—É–ª –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {prob:.3f}")
                        return prob
                except ValueError:
                    pass
                logging.warning(f"Grok –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: '{text}'")
            else:
                logging.error(f"Grok API –æ—à–∏–±–∫–∞ {response.status_code}: {response.text}")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Grok: {e}")

    return 0.5  # fallback


async def analyze(image_bytes=None, tf=None, symbol=None):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ ‚Äî —Ç–µ–ø–µ—Ä—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è.
    """
    logging.debug(f"–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞: image={bool(image_bytes)}, tf={tf}, symbol={symbol}")

    if image_bytes:
        candles, quality = extract_candles(image_bytes, max_candles=70)
        source = "—Å–∫—Ä–∏–Ω—à–æ—Ç –≥—Ä–∞—Ñ–∏–∫–∞"
        symbol = symbol or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç"
    else:
        try:
            candles = get_candles(symbol, interval=f"{tf}m", limit=70)
            source = "Twelve Data / Binance API"
            logging.debug(f"–ü–æ–ª—É—á–µ–Ω–æ {len(candles)} —Å–≤–µ—á–µ–π –∏–∑ API")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None, f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {str(e)}"
        quality = 1.0

    if len(candles) < 5:
        return None, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–µ—á–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–º–∏–Ω–∏–º—É–º 5)"

    features = build_features(candles, tf)
    if len(features) == 0:
        features = np.array([[0.1, 0, 0.1]])
        logging.warning("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã fallback-–ø—Ä–∏–∑–Ω–∞–∫–∏")
    X = features[-1].reshape(1, -1)

    model = get_model(tf)
    ml_prob = model.predict_proba(X)[0][1]

    patterns, pattern_score = detect_patterns(candles)
    trend_prob = trend_signal(candles)
    regime = market_regime(candles)

    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ Grok
    grok_prob = await call_grok(candles, patterns, regime, tf, symbol)

    # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞
    if regime == "trend":
        weights = [0.35, 0.15, 0.25, 0.25]
    elif regime == "flat":
        weights = [0.15, 0.40, 0.20, 0.25]
    else:
        weights = [0.25, 0.25, 0.25, 0.25]

    final_prob = np.dot(weights, [ml_prob, pattern_score, trend_prob, grok_prob])

    conf_label, conf_score = confidence_from_probs([ml_prob, pattern_score, trend_prob, grok_prob])

    return {
        "prob": round(final_prob, 3),
        "down_prob": round(1 - final_prob, 3),
        "confidence": conf_label,
        "confidence_score": conf_score,
        "regime": regime,
        "patterns": patterns,
        "tf": tf,
        "symbol": symbol,
        "source": source,
        "quality": quality
    }, None
