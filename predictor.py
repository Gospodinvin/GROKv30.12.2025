# predictor.py
import httpx
import os
import logging
from features import build_features
from patterns import detect_patterns
from trend import trend_signal, market_regime
from confidence import confidence_from_probs
from model_registry import get_model
from data_provider import get_candles
from cv_extractor import extract_candles
import numpy as np

# –ù–æ–≤—ã–π –∫–æ–¥: –∫–ª–∏–µ–Ω—Ç –¥–ª—è Grok API
XAI_API_KEY = os.getenv("XAI_API_KEY")
GROK_MODEL = "grok-4"  # –∏–ª–∏ "grok-beta", –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –Ω–∞ –º–æ–º–µ–Ω—Ç –∑–∞–ø—É—Å–∫–∞

async def call_grok(candles: list, patterns: list, regime: str, tf: str, symbol: str) -> float:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ Grok –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç 0.0 –¥–æ 1.0.
    """
    if not XAI_API_KEY:
        logging.warning("XAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—ã–∑–æ–≤ Grok")
        return 0.5

    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–≤–µ—á–µ–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤)
    recent_candles = candles[-10:]
    candle_desc = []
    for i, c in enumerate(recent_candles):
        direction = "üü¢" if c["close"] > c["open"] else "üî¥"
        body = abs(c["close"] - c["open"])
        candle_desc.append(f"{i+1}: {direction} O:{c['open']:.4f} H:{c['high']:.4f} L:{c['low']:.4f} C:{c['close']:.4f} (body {body:.4f})")

    prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä—ã–Ω–∫–æ–≤.
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {symbol}
–¢–∞–π–º—Ñ—Ä–µ–π–º: {tf} –º–∏–Ω—É—Ç
–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º —Ä—ã–Ω–∫–∞: {regime} ({'—Ç—Ä–µ–Ω–¥' if regime == 'trend' else '—Ñ–ª—ç—Ç' if regime == 'flat' else '–≤—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å'})

–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–≤–µ—á–µ–π (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ü–µ–Ω—ã, –æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º):
{chr(10).join(candle_desc)}

–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(patterns) if patterns else '–Ω–µ—Ç –∑–Ω–∞—á–∏–º—ã—Ö'}

–ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ —Ü–µ–Ω—ã –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ 2‚Äì3 —Å–≤–µ—á–∏ (–Ω–∞ —Ç–æ–º –∂–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ).
–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ–¥–Ω–∏–º —á–∏—Å–ª–æ–º –æ—Ç 0.00 –¥–æ 1.00 (–Ω–∞–ø—Ä–∏–º–µ—Ä: 0.72).
–ù–µ –¥–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏–π, —Å–∏–º–≤–æ–ª–æ–≤ –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞.
"""

    try:
        async with httpx.AsyncClient(timeout=15.0) as client:
            response = await client.post(
                "https://api.x.ai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {XAI_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": GROK_MODEL,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.3,  # –Ω–∏–∑–∫–∞—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    "max_tokens": 10
                }
            )

            if response.status_code == 200:
                text = response.json()["choices"][0]["message"]["content"].strip()
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ
                prob = float(text)
                if 0.0 <= prob <= 1.0:
                    logging.info(f"Grok –≤–µ—Ä–Ω—É–ª –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {prob:.3f}")
                    return prob
                else:
                    logging.warning(f"Grok –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {text}")
                    return 0.5
            else:
                logging.error(f"Grok API error {response.status_code}: {response.text}")
                return 0.5

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ Grok: {e}")
        return 0.5


def analyze(image_bytes=None, tf=None, symbol=None):
    logging.debug(f"Starting analyze: image_bytes={bool(image_bytes)}, tf={tf}, symbol={symbol}")
    
    if image_bytes:
        candles, quality = extract_candles(image_bytes, max_candles=70)
        source = "—Å–∫—Ä–∏–Ω—à–æ—Ç –≥—Ä–∞—Ñ–∏–∫–∞"
        symbol = symbol or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç"
    else:
        try:
            candles = get_candles(symbol, interval=f"{tf}m", limit=70)
            source = "Twelve Data / Binance API"
            logging.debug(f"–ü–æ–ª—É—á–µ–Ω–æ {len(candles)} —Å–≤–µ—á–µ–π –∏–∑ API")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ analyze: {str(e)}")
            return None, f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {str(e)}"
        quality = 1.0

    if len(candles) < 5:
        return None, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–µ—á–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–º–∏–Ω–∏–º—É–º 5)"

    features = build_features(candles, tf)
    if len(features) == 0:
        features = np.array([[0.1, 0, 0.1]])
    X = features[-1].reshape(1, -1)

    model = get_model(tf)
    ml_prob = model.predict_proba(X)[0][1]

    patterns, pattern_score = detect_patterns(candles)
    trend_prob = trend_signal(candles)
    regime = market_regime(candles)

    # –ù–æ–≤—ã–π –≤—ã–∑–æ–≤ Grok (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ ‚Äî –Ω–æ –≤ —Ç–µ–∫—É—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ aiogram –∏—Å–ø–æ–ª—å–∑—É–µ—Ç sync)
    # –ü–æ—ç—Ç–æ–º—É –¥–µ–ª–∞–µ–º –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ asyncio.run (–¥–æ–ø—É—Å—Ç–∏–º–æ –≤ –±–æ—Ç–µ)
    import asyncio
    grok_prob = asyncio.run(call_grok(candles, patterns, regime, tf, symbol))

    # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ —Å —É—á—ë—Ç–æ–º Grok
    if regime == "trend":
        weights = [0.35, 0.15, 0.25, 0.25]  # –±–æ–ª—å—à–µ –≤–µ—Å–∞ ML –∏ Grok
    elif regime == "flat":
        weights = [0.15, 0.40, 0.20, 0.25]  # –±–æ–ª—å—à–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º –∏ Grok
    else:
        weights = [0.25, 0.25, 0.25, 0.25]  # —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ

    final_prob = np.dot(weights, [ml_prob, pattern_score, trend_prob, grok_prob])

    conf_label, conf_score = confidence_from_probs([ml_prob, pattern_score, trend_prob, grok_prob])

    return {
        "prob": round(final_prob, 3),
        "down_prob": round(1 - final_prob, 3),
        "confidence": conf_label,
        "confidence_score": conf_score,
        "regime": regime,
        "patterns": patterns,
        "tf": tf,
        "symbol": symbol,
        "source": source,
        "quality": quality
    }, None
